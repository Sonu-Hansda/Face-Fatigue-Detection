{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08f26b4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Download\n",
    "!wget -O face_landmarker_v2_with_blendshapes.task -q https://storage.googleapis.com/mediapipe-models/face_landmarker/face_landmarker/float16/1/face_landmarker.task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2002802d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download packages\n",
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3acde479",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Packages\n",
    "import cv2\n",
    "import mediapipe as mp\n",
    "import numpy as np\n",
    "import time\n",
    "import sqlite3\n",
    "\n",
    "from mediapipe.tasks import python\n",
    "from mediapipe.tasks.python import vision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "31b6d517",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SQL Connection\n",
    "conn = sqlite3.connect(\"fatigue_data.sqlite\")\n",
    "cursor = conn.cursor()\n",
    "\n",
    "cursor.execute(\"\"\"\n",
    "CREATE TABLE IF NOT EXISTS fatigue_data (\n",
    "    id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
    "    timestamp REAL,\n",
    "    ear REAL,\n",
    "    mar REAL,\n",
    "    roll REAL,\n",
    "    pitch REAL,\n",
    "    label INTEGER\n",
    ")\n",
    "\"\"\")\n",
    "conn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "37205087",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "W0000 00:00:1771060890.263230  111699 face_landmarker_graph.cc:174] Sets FaceBlendshapesGraph acceleration to xnnpack by default.\n",
      "INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n",
      "W0000 00:00:1771060890.273121  111705 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1771060890.288486  111708 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n"
     ]
    }
   ],
   "source": [
    "# ---------- Load Model ----------\n",
    "base_options = python.BaseOptions(model_asset_path='face_landmarker_v2_with_blendshapes.task')\n",
    "\n",
    "# Model Configuration(s)\n",
    "options = vision.FaceLandmarkerOptions(\n",
    "    base_options=base_options,\n",
    "    running_mode=vision.RunningMode.VIDEO,\n",
    "    num_faces=1,\n",
    "    output_face_blendshapes=False,\n",
    "    output_facial_transformation_matrixes=False\n",
    ")\n",
    "\n",
    "landmarker = vision.FaceLandmarker.create_from_options(options)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "eecc2d43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utility Functions\n",
    "def calculate_angle(p1, p2):\n",
    "    dx = p2[0] - p1[0]\n",
    "    dy = p2[1] - p1[1]\n",
    "    return np.degrees(np.arctan2(dy, dx))\n",
    "\n",
    "def euclidean(p1, p2):\n",
    "    return np.linalg.norm(np.array(p1) - np.array(p2))\n",
    "\n",
    "def calculate_ear(eye_pts):\n",
    "    p1, p2, p3, p4, p5, p6 = eye_pts\n",
    "    return (euclidean(p2,p6) + euclidean(p3,p5)) / (2.0 * euclidean(p1,p4))\n",
    "\n",
    "def calculate_mar(mouth_pts):\n",
    "    p1, p2, p3, p4, p5, p6 = mouth_pts[:6]\n",
    "    return (euclidean(p2,p6) + euclidean(p3,p5)) / (2.0 * euclidean(p1,p4))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a72736e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------- Landmark Indices ----------------------\n",
    "LEFT_EYE = [33, 160, 158, 133, 153, 144]\n",
    "RIGHT_EYE = [362, 385, 387, 263, 373, 380]\n",
    "MOUTH = [13, 14, 78, 308, 82, 312, 87, 317]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "31dd1bf7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "QFontDatabase: Cannot find font directory /home/sonu/Desktop/fatigue/.venv/lib/python3.10/site-packages/cv2/qt/fonts.\n",
      "Note that Qt no longer ships fonts. Deploy some (from https://dejavu-fonts.github.io/ for example) or switch to fontconfig.\n",
      "QFontDatabase: Cannot find font directory /home/sonu/Desktop/fatigue/.venv/lib/python3.10/site-packages/cv2/qt/fonts.\n",
      "Note that Qt no longer ships fonts. Deploy some (from https://dejavu-fonts.github.io/ for example) or switch to fontconfig.\n",
      "QFontDatabase: Cannot find font directory /home/sonu/Desktop/fatigue/.venv/lib/python3.10/site-packages/cv2/qt/fonts.\n",
      "Note that Qt no longer ships fonts. Deploy some (from https://dejavu-fonts.github.io/ for example) or switch to fontconfig.\n",
      "QFontDatabase: Cannot find font directory /home/sonu/Desktop/fatigue/.venv/lib/python3.10/site-packages/cv2/qt/fonts.\n",
      "Note that Qt no longer ships fonts. Deploy some (from https://dejavu-fonts.github.io/ for example) or switch to fontconfig.\n",
      "QFontDatabase: Cannot find font directory /home/sonu/Desktop/fatigue/.venv/lib/python3.10/site-packages/cv2/qt/fonts.\n",
      "Note that Qt no longer ships fonts. Deploy some (from https://dejavu-fonts.github.io/ for example) or switch to fontconfig.\n"
     ]
    }
   ],
   "source": [
    "cap = cv2.VideoCapture(0)\n",
    "cv2.namedWindow(\"Fatigue Data Collector\", cv2.WINDOW_NORMAL)\n",
    "\n",
    "recording = False\n",
    "waiting_for_label = False\n",
    "recorded_data = []\n",
    "record_start_time = None\n",
    "message = \"Press R to start recording | Q to quit\"\n",
    "\n",
    "global_start_time = time.time()\n",
    "\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    frame = cv2.flip(frame, 1)\n",
    "    mesh_frame = frame.copy()\n",
    "\n",
    "    rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    mp_image = mp.Image(image_format=mp.ImageFormat.SRGB, data=rgb_frame)\n",
    "    timestamp = int((time.time() - global_start_time) * 1000)\n",
    "\n",
    "    result = landmarker.detect_for_video(mp_image, timestamp)\n",
    "\n",
    "    if result.face_landmarks:\n",
    "        face_landmarks = result.face_landmarks[0]\n",
    "        h, w, _ = frame.shape\n",
    "\n",
    "        nose = face_landmarks[1]\n",
    "        left_eye_outer = face_landmarks[33]\n",
    "        right_eye_outer = face_landmarks[263]\n",
    "        chin = face_landmarks[152]\n",
    "\n",
    "        nose_pt = (int(nose.x * w), int(nose.y * h))\n",
    "        left_eye_pt = (int(left_eye_outer.x * w), int(left_eye_outer.y * h))\n",
    "        right_eye_pt = (int(right_eye_outer.x * w), int(right_eye_outer.y * h))\n",
    "        chin_pt = (int(chin.x * w), int(chin.y * h))\n",
    "\n",
    "        roll_angle = calculate_angle(left_eye_pt, right_eye_pt)\n",
    "        pitch_distance = chin_pt[1] - nose_pt[1]\n",
    "\n",
    "        left_eye_pts = [(int(face_landmarks[i].x*w), int(face_landmarks[i].y*h)) for i in LEFT_EYE]\n",
    "        right_eye_pts = [(int(face_landmarks[i].x*w), int(face_landmarks[i].y*h)) for i in RIGHT_EYE]\n",
    "        mouth_pts = [(int(face_landmarks[i].x*w), int(face_landmarks[i].y*h)) for i in MOUTH]\n",
    "\n",
    "        ear = (calculate_ear(left_eye_pts) + calculate_ear(right_eye_pts)) / 2.0\n",
    "        mar = calculate_mar(mouth_pts)\n",
    "        \n",
    "                # -------- Draw Eye Landmarks (Green) --------\n",
    "        for pt in left_eye_pts + right_eye_pts:\n",
    "            cv2.circle(mesh_frame, pt, 3, (0, 255, 0), -1)\n",
    "\n",
    "        # -------- Draw Mouth Landmarks (Red) --------\n",
    "        for pt in mouth_pts:\n",
    "            cv2.circle(mesh_frame, pt, 3, (0, 0, 255), -1)\n",
    "\n",
    "        # -------- Draw Head Tilt Lines --------\n",
    "        cv2.line(mesh_frame, left_eye_pt, right_eye_pt, (255, 0, 0), 2)\n",
    "        cv2.line(mesh_frame, nose_pt, chin_pt, (255, 255, 0), 2)\n",
    "\n",
    "        # Optional: Show feature values\n",
    "        cv2.putText(mesh_frame, f\"EAR: {ear:.3f}\", (30, 80),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 255), 2)\n",
    "\n",
    "        cv2.putText(mesh_frame, f\"MAR: {mar:.3f}\", (30, 110),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 255), 2)\n",
    "\n",
    "        cv2.putText(mesh_frame, f\"Roll: {roll_angle:.2f}\", (30, 140),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 255), 2)\n",
    "\n",
    "\n",
    "        if recording:\n",
    "            recorded_data.append((timestamp, ear, mar, roll_angle, pitch_distance))\n",
    "\n",
    "    # ---------------------- UI STATES ----------------------\n",
    "\n",
    "    if recording:\n",
    "        elapsed = int(time.time() - record_start_time)\n",
    "        remaining = 5 - elapsed\n",
    "\n",
    "        cv2.putText(mesh_frame, f\"REC ‚óè {remaining}s\", (30, 40),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 3)\n",
    "\n",
    "        if remaining <= 0:\n",
    "            recording = False\n",
    "            waiting_for_label = True\n",
    "            message = \"Press 0 = Normal | 1 = Fatigue\"\n",
    "\n",
    "    elif waiting_for_label:\n",
    "        cv2.putText(mesh_frame, message, (30, 40),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 255, 255), 2)\n",
    "\n",
    "    else:\n",
    "        cv2.putText(mesh_frame, message, (30, 40),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 0.8, (255, 255, 255), 2)\n",
    "\n",
    "    combined = np.hstack((frame, mesh_frame))\n",
    "    cv2.imshow(\"Fatigue Data Collector\", combined)\n",
    "\n",
    "    key = cv2.waitKey(1) & 0xFF\n",
    "\n",
    "    if key == ord('r') and not recording and not waiting_for_label:\n",
    "        recording = True\n",
    "        record_start_time = time.time()\n",
    "        recorded_data = []\n",
    "        message = \"\"\n",
    "\n",
    "    elif key == ord('0') and waiting_for_label:\n",
    "        for row in recorded_data:\n",
    "            cursor.execute(\"INSERT INTO fatigue_data (timestamp, ear, mar, roll, pitch, label) VALUES (?, ?, ?, ?, ?, ?)\",\n",
    "                           (*row, 0))\n",
    "        conn.commit()\n",
    "        waiting_for_label = False\n",
    "        message = \"Saved as NORMAL | Press R to record again\"\n",
    "\n",
    "    elif key == ord('1') and waiting_for_label:\n",
    "        for row in recorded_data:\n",
    "            cursor.execute(\"INSERT INTO fatigue_data (timestamp, ear, mar, roll, pitch, label) VALUES (?, ?, ?, ?, ?, ?)\",\n",
    "                           (*row, 1))\n",
    "        conn.commit()\n",
    "        waiting_for_label = False\n",
    "        message = \"Saved as FATIGUE | Press R to record again\"\n",
    "\n",
    "    elif key == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8f281ae6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>ear</th>\n",
       "      <th>mar</th>\n",
       "      <th>roll</th>\n",
       "      <th>pitch</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>13041.0</td>\n",
       "      <td>0.298366</td>\n",
       "      <td>0.519745</td>\n",
       "      <td>1.181189</td>\n",
       "      <td>76.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>13077.0</td>\n",
       "      <td>0.294782</td>\n",
       "      <td>0.523849</td>\n",
       "      <td>1.193489</td>\n",
       "      <td>76.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>13109.0</td>\n",
       "      <td>0.297783</td>\n",
       "      <td>0.520574</td>\n",
       "      <td>1.193489</td>\n",
       "      <td>76.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>13141.0</td>\n",
       "      <td>0.297694</td>\n",
       "      <td>0.520574</td>\n",
       "      <td>0.596809</td>\n",
       "      <td>76.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>13177.0</td>\n",
       "      <td>0.296279</td>\n",
       "      <td>0.542947</td>\n",
       "      <td>0.596809</td>\n",
       "      <td>76.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>13209.0</td>\n",
       "      <td>0.296279</td>\n",
       "      <td>0.544879</td>\n",
       "      <td>0.596809</td>\n",
       "      <td>76.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>13241.0</td>\n",
       "      <td>0.295070</td>\n",
       "      <td>0.544726</td>\n",
       "      <td>0.596809</td>\n",
       "      <td>76.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>13277.0</td>\n",
       "      <td>0.295070</td>\n",
       "      <td>0.520428</td>\n",
       "      <td>0.596809</td>\n",
       "      <td>76.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>13309.0</td>\n",
       "      <td>0.289809</td>\n",
       "      <td>0.520428</td>\n",
       "      <td>0.590657</td>\n",
       "      <td>76.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>13341.0</td>\n",
       "      <td>0.281253</td>\n",
       "      <td>0.546044</td>\n",
       "      <td>0.590657</td>\n",
       "      <td>76.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  timestamp       ear       mar      roll  pitch  label\n",
       "0   1    13041.0  0.298366  0.519745  1.181189   76.0      0\n",
       "1   2    13077.0  0.294782  0.523849  1.193489   76.0      0\n",
       "2   3    13109.0  0.297783  0.520574  1.193489   76.0      0\n",
       "3   4    13141.0  0.297694  0.520574  0.596809   76.0      0\n",
       "4   5    13177.0  0.296279  0.542947  0.596809   76.0      0\n",
       "5   6    13209.0  0.296279  0.544879  0.596809   76.0      0\n",
       "6   7    13241.0  0.295070  0.544726  0.596809   76.0      0\n",
       "7   8    13277.0  0.295070  0.520428  0.596809   76.0      0\n",
       "8   9    13309.0  0.289809  0.520428  0.590657   76.0      0\n",
       "9  10    13341.0  0.281253  0.546044  0.590657   76.0      0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sqlite3\n",
    "import pandas as pd\n",
    "\n",
    "# Connect to database\n",
    "conn = sqlite3.connect(\"fatigue_data.sqlite\")\n",
    "\n",
    "# Read full table into pandas dataframe\n",
    "df = pd.read_sql_query(\"SELECT * FROM fatigue_data\", conn)\n",
    "\n",
    "conn.close()\n",
    "\n",
    "# Show first 10 rows\n",
    "df.head(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2f8e2321",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0000 00:00:1771092061.657271   57853 face_landmarker_graph.cc:174] Sets FaceBlendshapesGraph acceleration to xnnpack by default.\n",
      "W0000 00:00:1771092061.664285   57859 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1771092061.683108   57865 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Simple Fatigue Detection System\n",
      "============================================================\n",
      "LEFT SIDE: Normal Video with Fatigue Analytics\n",
      "RIGHT SIDE: Analyzed View with Face Mesh Detection\n",
      "============================================================\n",
      "- EAR threshold: 0.25 (Eye closure detection)\n",
      "- MAR threshold: 0.6 (Yawning detection)\n",
      "- Head tilt threshold: 15¬∞\n",
      "------------------------------------------------------------\n",
      "Press 'q' to quit\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import numpy as np\n",
    "import time\n",
    "from collections import deque\n",
    "from dataclasses import dataclass\n",
    "from typing import Tuple\n",
    "\n",
    "from mediapipe.tasks import python\n",
    "from mediapipe.tasks.python import vision\n",
    "\n",
    "@dataclass\n",
    "class FatigueState:\n",
    "    is_fatigued: bool = False\n",
    "    fatigue_level: float = 0.0  # 0-100%\n",
    "    alerts: list = None\n",
    "    \n",
    "    def __post_init__(self):\n",
    "        self.alerts = []\n",
    "\n",
    "class SimpleFatigueDetector:\n",
    "    def __init__(self):\n",
    "        # Simple threshold-based rules\n",
    "        self.EAR_THRESHOLD = 0.25  # Eye Aspect Ratio threshold (lower = more closed)\n",
    "        self.MAR_THRESHOLD = 0.6   # Mouth Aspect Ratio threshold (higher = more yawn-like)\n",
    "        self.HEAD_TILT_THRESHOLD = 15  # Degrees of head tilt\n",
    "        \n",
    "        # Temporal smoothing (look at last N frames)\n",
    "        self.history_size = 30  # About 1 second at 30fps\n",
    "        self.ear_history = deque(maxlen=self.history_size)\n",
    "        self.mar_history = deque(maxlen=self.history_size)\n",
    "        self.head_tilt_history = deque(maxlen=self.history_size)\n",
    "        \n",
    "        # Fatigue counters\n",
    "        self.consecutive_closed_eyes = 0\n",
    "        self.CLOSED_EYE_THRESHOLD = 15  # Frames\n",
    "        \n",
    "        # Alert cooldown (to avoid spam)\n",
    "        self.last_alert_time = 0\n",
    "        self.alert_cooldown = 5  # seconds\n",
    "        \n",
    "    def update_histories(self, ear, mar, head_tilt):\n",
    "        self.ear_history.append(ear)\n",
    "        self.mar_history.append(mar)\n",
    "        self.head_tilt_history.append(head_tilt)\n",
    "    \n",
    "    def check_eye_closed(self, ear) -> Tuple[bool, str]:\n",
    "        \"\"\"Check if eyes are closed or nearly closed\"\"\"\n",
    "        if ear < self.EAR_THRESHOLD:\n",
    "            self.consecutive_closed_eyes += 1\n",
    "            if self.consecutive_closed_eyes > self.CLOSED_EYE_THRESHOLD:\n",
    "                return True, f\"Eyes closed for {self.consecutive_closed_eyes} frames\"\n",
    "        else:\n",
    "            self.consecutive_closed_eyes = max(0, self.consecutive_closed_eyes - 2)\n",
    "        return False, \"\"\n",
    "    \n",
    "    def check_yawn(self, mar) -> Tuple[bool, str]:\n",
    "        \"\"\"Check for yawning (high MAR)\"\"\"\n",
    "        if mar > self.MAR_THRESHOLD:\n",
    "            # Check if it's sustained (look at recent history)\n",
    "            recent_mar = list(self.mar_history)[-10:]\n",
    "            if len(recent_mar) >= 5 and sum(m > self.MAR_THRESHOLD for m in recent_mar) >= 3:\n",
    "                return True, \"Possible yawning detected\"\n",
    "        return False, \"\"\n",
    "    \n",
    "    def check_head_tilt(self, head_tilt) -> Tuple[bool, str]:\n",
    "        \"\"\"Check for excessive head tilting (looking down/drooping)\"\"\"\n",
    "        if abs(head_tilt) > self.HEAD_TILT_THRESHOLD:\n",
    "            return True, f\"Excessive head tilt: {head_tilt:.1f}¬∞\"\n",
    "        return False, \"\"\n",
    "    \n",
    "    def check_fatigue_trend(self) -> Tuple[bool, str]:\n",
    "        \"\"\"Check for gradual fatigue indicators (trends)\"\"\"\n",
    "        if len(self.ear_history) < self.history_size:\n",
    "            return False, \"\"\n",
    "        \n",
    "        # Check if EAR is trending downward (eyes getting more closed)\n",
    "        ear_list = list(self.ear_history)\n",
    "        first_half_ear = np.mean(ear_list[:15])\n",
    "        second_half_ear = np.mean(ear_list[15:])\n",
    "        \n",
    "        if second_half_ear < first_half_ear * 0.8:  # 20% decrease\n",
    "            return True, \"Eyes gradually closing\"\n",
    "        \n",
    "        return False, \"\"\n",
    "    \n",
    "    def detect(self, ear, mar, head_tilt, current_time) -> FatigueState:\n",
    "        \"\"\"Main detection function\"\"\"\n",
    "        state = FatigueState()\n",
    "        \n",
    "        # Update histories\n",
    "        self.update_histories(ear, mar, head_tilt)\n",
    "        \n",
    "        # Check individual rules\n",
    "        eye_closed, eye_msg = self.check_eye_closed(ear)\n",
    "        yawning, yawn_msg = self.check_yawn(mar)\n",
    "        head_tilted, tilt_msg = self.check_head_tilt(head_tilt)\n",
    "        trend_fatigue, trend_msg = self.check_fatigue_trend()\n",
    "        \n",
    "        # Collect alerts (with cooldown)\n",
    "        if current_time - self.last_alert_time > self.alert_cooldown:\n",
    "            if eye_closed:\n",
    "                state.alerts.append((\"‚ö†Ô∏è DROWSY\", eye_msg))\n",
    "            if yawning:\n",
    "                state.alerts.append((\"üòÆ YAWNING\", yawn_msg))\n",
    "            if head_tilted:\n",
    "                state.alerts.append((\"üò¥ HEAD DROOP\", tilt_msg))\n",
    "            if trend_fatigue:\n",
    "                state.alerts.append((\"‚ö†Ô∏è FATIGUE TREND\", trend_msg))\n",
    "            \n",
    "            if state.alerts:\n",
    "                self.last_alert_time = current_time\n",
    "        \n",
    "        # Calculate fatigue level (0-100%)\n",
    "        fatigue_factors = []\n",
    "        \n",
    "        # Factor 1: EAR (lower = more fatigue)\n",
    "        ear_factor = max(0, min(1, (0.35 - ear) / 0.2))  # Normalize around 0.35\n",
    "        fatigue_factors.append(ear_factor)\n",
    "        \n",
    "        # Factor 2: MAR (higher = more fatigue from yawning)\n",
    "        mar_factor = max(0, min(1, (mar - 0.4) / 0.3))  # Normalize around 0.4\n",
    "        fatigue_factors.append(mar_factor * 0.7)  # Weight yawn less than eyes\n",
    "        \n",
    "        # Factor 3: Head tilt (extreme tilt = fatigue)\n",
    "        tilt_factor = max(0, min(1, abs(head_tilt) / 30))\n",
    "        fatigue_factors.append(tilt_factor * 0.5)  # Weight tilt less\n",
    "        \n",
    "        # Factor 4: Consecutive closed eyes\n",
    "        if self.consecutive_closed_eyes > 0:\n",
    "            closed_factor = min(1, self.consecutive_closed_eyes / 30)\n",
    "            fatigue_factors.append(closed_factor)\n",
    "        \n",
    "        # Calculate overall fatigue level\n",
    "        if fatigue_factors:\n",
    "            state.fatigue_level = min(100, np.mean(fatigue_factors) * 100)\n",
    "        \n",
    "        # Final fatigue decision\n",
    "        state.is_fatigued = (\n",
    "            eye_closed or \n",
    "            (yawning and head_tilted) or \n",
    "            state.fatigue_level > 60\n",
    "        )\n",
    "        \n",
    "        return state\n",
    "\n",
    "# ---------- Load Model ----------\n",
    "base_options = python.BaseOptions(model_asset_path='face_landmarker_v2_with_blendshapes.task')\n",
    "options = vision.FaceLandmarkerOptions(\n",
    "    base_options=base_options,\n",
    "    running_mode=vision.RunningMode.VIDEO,\n",
    "    num_faces=1,\n",
    "    output_face_blendshapes=False,\n",
    "    output_facial_transformation_matrixes=False\n",
    ")\n",
    "landmarker = vision.FaceLandmarker.create_from_options(options)\n",
    "\n",
    "# Utility Functions\n",
    "def calculate_angle(p1, p2):\n",
    "    dx = p2[0] - p1[0]\n",
    "    dy = p2[1] - p1[1]\n",
    "    return np.degrees(np.arctan2(dy, dx))\n",
    "\n",
    "def euclidean(p1, p2):\n",
    "    return np.linalg.norm(np.array(p1) - np.array(p2))\n",
    "\n",
    "def calculate_ear(eye_pts):\n",
    "    p1, p2, p3, p4, p5, p6 = eye_pts\n",
    "    return (euclidean(p2,p6) + euclidean(p3,p5)) / (2.0 * euclidean(p1,p4))\n",
    "\n",
    "def calculate_mar(mouth_pts):\n",
    "    p1, p2, p3, p4, p5, p6 = mouth_pts[:6]\n",
    "    return (euclidean(p2,p6) + euclidean(p3,p5)) / (2.0 * euclidean(p1,p4))\n",
    "\n",
    "# Landmark Indices\n",
    "LEFT_EYE = [33, 160, 158, 133, 153, 144]\n",
    "RIGHT_EYE = [362, 385, 387, 263, 373, 380]\n",
    "MOUTH = [13, 14, 78, 308, 82, 312, 87, 317]\n",
    "\n",
    "# Initialize detector\n",
    "detector = SimpleFatigueDetector()\n",
    "\n",
    "# Start video capture\n",
    "cap = cv2.VideoCapture(0)\n",
    "cv2.namedWindow(\"Fatigue Detection System\", cv2.WINDOW_NORMAL)\n",
    "global_start_time = time.time()\n",
    "\n",
    "print(\"Simple Fatigue Detection System\")\n",
    "print(\"=\" * 60)\n",
    "print(\"LEFT SIDE: Normal Video with Fatigue Analytics\")\n",
    "print(\"RIGHT SIDE: Analyzed View with Face Mesh Detection\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"- EAR threshold: {detector.EAR_THRESHOLD} (Eye closure detection)\")\n",
    "print(f\"- MAR threshold: {detector.MAR_THRESHOLD} (Yawning detection)\")\n",
    "print(f\"- Head tilt threshold: {detector.HEAD_TILT_THRESHOLD}¬∞\")\n",
    "print(\"-\" * 60)\n",
    "print(\"Press 'q' to quit\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "    \n",
    "    frame = cv2.flip(frame, 1)\n",
    "    \n",
    "    # Create a copy for mesh visualization\n",
    "    mesh_frame = frame.copy()\n",
    "    \n",
    "    rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    mp_image = mp.Image(image_format=mp.ImageFormat.SRGB, data=rgb_frame)\n",
    "    timestamp = int((time.time() - global_start_time) * 1000)\n",
    "    \n",
    "    result = landmarker.detect_for_video(mp_image, timestamp)\n",
    "    \n",
    "    if result.face_landmarks:\n",
    "        face_landmarks = result.face_landmarks[0]\n",
    "        h, w, _ = frame.shape\n",
    "        \n",
    "        # Extract points\n",
    "        nose = face_landmarks[1]\n",
    "        left_eye_outer = face_landmarks[33]\n",
    "        right_eye_outer = face_landmarks[263]\n",
    "        chin = face_landmarks[152]\n",
    "        \n",
    "        nose_pt = (int(nose.x * w), int(nose.y * h))\n",
    "        left_eye_pt = (int(left_eye_outer.x * w), int(left_eye_outer.y * h))\n",
    "        right_eye_pt = (int(right_eye_outer.x * w), int(right_eye_outer.y * h))\n",
    "        chin_pt = (int(chin.x * w), int(chin.y * h))\n",
    "        \n",
    "        # Calculate metrics\n",
    "        roll_angle = calculate_angle(left_eye_pt, right_eye_pt)\n",
    "        pitch_distance = chin_pt[1] - nose_pt[1]\n",
    "        \n",
    "        left_eye_pts = [(int(face_landmarks[i].x*w), int(face_landmarks[i].y*h)) for i in LEFT_EYE]\n",
    "        right_eye_pts = [(int(face_landmarks[i].x*w), int(face_landmarks[i].y*h)) for i in RIGHT_EYE]\n",
    "        mouth_pts = [(int(face_landmarks[i].x*w), int(face_landmarks[i].y*h)) for i in MOUTH]\n",
    "        \n",
    "        ear = (calculate_ear(left_eye_pts) + calculate_ear(right_eye_pts)) / 2.0\n",
    "        mar = calculate_mar(mouth_pts)\n",
    "        \n",
    "        # Detect fatigue\n",
    "        current_time = time.time()\n",
    "        fatigue_state = detector.detect(ear, mar, roll_angle, current_time)\n",
    "        \n",
    "        # ========== LEFT SIDE: Normal Video with Analytics ==========\n",
    "        normal_view = frame.copy()\n",
    "        \n",
    "        # Add header for left side\n",
    "        cv2.putText(normal_view, \"LIVE FEED - FATIGUE ANALYTICS\", (30, 30), \n",
    "                   cv2.FONT_HERSHEY_SIMPLEX, 0.8, (255, 255, 255), 2)\n",
    "        \n",
    "        # Display metrics with descriptions\n",
    "        y_offset = 80\n",
    "        \n",
    "        # EAR with description\n",
    "        cv2.putText(normal_view, f\"EAR (Eye Aspect Ratio): {ear:.3f}\", (30, y_offset), \n",
    "                   cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 255), 2)\n",
    "        cv2.putText(normal_view, f\"  ‚Üí Measures eye openness (lower = more closed)\", (30, y_offset+20), \n",
    "                   cv2.FONT_HERSHEY_SIMPLEX, 0.4, (200, 200, 200), 1)\n",
    "        \n",
    "        # MAR with description\n",
    "        cv2.putText(normal_view, f\"MAR (Mouth Aspect Ratio): {mar:.3f}\", (30, y_offset+50), \n",
    "                   cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 255), 2)\n",
    "        cv2.putText(normal_view, f\"  ‚Üí Measures mouth openness (higher = yawning)\", (30, y_offset+70), \n",
    "                   cv2.FONT_HERSHEY_SIMPLEX, 0.4, (200, 200, 200), 1)\n",
    "        \n",
    "        # Head tilt with description\n",
    "        cv2.putText(normal_view, f\"Head Tilt: {roll_angle:.1f}¬∞\", (30, y_offset+100), \n",
    "                   cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 255), 2)\n",
    "        cv2.putText(normal_view, f\"  ‚Üí Head angle (higher = drooping)\", (30, y_offset+120), \n",
    "                   cv2.FONT_HERSHEY_SIMPLEX, 0.4, (200, 200, 200), 1)\n",
    "        \n",
    "        # Fatigue level bar with description\n",
    "        bar_length = 250\n",
    "        filled_length = int(bar_length * fatigue_state.fatigue_level / 100)\n",
    "        bar_color = (0, 255, 0) if fatigue_state.fatigue_level < 40 else (0, 255, 255) if fatigue_state.fatigue_level < 70 else (0, 0, 255)\n",
    "        \n",
    "        cv2.putText(normal_view, \"Fatigue Level:\", (30, y_offset+160), \n",
    "                   cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 255), 2)\n",
    "        cv2.rectangle(normal_view, (30, y_offset+170), (30+filled_length, y_offset+190), bar_color, -1)\n",
    "        cv2.rectangle(normal_view, (30, y_offset+170), (30+bar_length, y_offset+190), (255, 255, 255), 2)\n",
    "        cv2.putText(normal_view, f\"{fatigue_state.fatigue_level:.0f}%\", (30+bar_length+10, y_offset+185), \n",
    "                   cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 255), 2)\n",
    "        \n",
    "        # Status indicators with descriptions\n",
    "        status_y = y_offset + 220\n",
    "        \n",
    "        # Eye status\n",
    "        eye_status = \"CLOSED\" if ear < detector.EAR_THRESHOLD else \"OPEN\"\n",
    "        eye_color = (0, 0, 255) if ear < detector.EAR_THRESHOLD else (0, 255, 0)\n",
    "        cv2.putText(normal_view, f\"Eyes: {eye_status}\", (30, status_y), \n",
    "                   cv2.FONT_HERSHEY_SIMPLEX, 0.6, eye_color, 2)\n",
    "        \n",
    "        # Mouth status\n",
    "        mouth_status = \"YAWNING\" if mar > detector.MAR_THRESHOLD else \"NORMAL\"\n",
    "        mouth_color = (0, 0, 255) if mar > detector.MAR_THRESHOLD else (0, 255, 0)\n",
    "        cv2.putText(normal_view, f\"Mouth: {mouth_status}\", (30, status_y+30), \n",
    "                   cv2.FONT_HERSHEY_SIMPLEX, 0.6, mouth_color, 2)\n",
    "        \n",
    "        # Head status\n",
    "        head_status = \"TILTED\" if abs(roll_angle) > detector.HEAD_TILT_THRESHOLD else \"NORMAL\"\n",
    "        head_color = (0, 0, 255) if abs(roll_angle) > detector.HEAD_TILT_THRESHOLD else (0, 255, 0)\n",
    "        cv2.putText(normal_view, f\"Head: {head_status}\", (30, status_y+60), \n",
    "                   cv2.FONT_HERSHEY_SIMPLEX, 0.6, head_color, 2)\n",
    "        \n",
    "        # Alerts on left side\n",
    "        if fatigue_state.alerts:\n",
    "            alert_y = status_y + 100\n",
    "            cv2.putText(normal_view, \"ACTIVE ALERTS:\", (30, alert_y), \n",
    "                       cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 255), 2)\n",
    "            for i, (alert_type, msg) in enumerate(fatigue_state.alerts):\n",
    "                cv2.putText(normal_view, f\"{alert_type}\", (30, alert_y+30 + i*25), \n",
    "                           cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 0, 255), 2)\n",
    "                cv2.putText(normal_view, f\"  {msg}\", (30, alert_y+50 + i*25), \n",
    "                           cv2.FONT_HERSHEY_SIMPLEX, 0.4, (200, 200, 200), 1)\n",
    "        \n",
    "        # ========== RIGHT SIDE: Mesh View with Detection Visualization ==========\n",
    "        mesh_view = mesh_frame\n",
    "        \n",
    "        # Add header for right side\n",
    "        cv2.putText(mesh_view, \"FACE MESH ANALYSIS\", (30, 30), \n",
    "                   cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 255, 255), 2)\n",
    "        \n",
    "        # Draw eye landmarks with color coding\n",
    "        for pt in left_eye_pts + right_eye_pts:\n",
    "            color = (0, 255, 0) if ear > detector.EAR_THRESHOLD else (0, 0, 255)\n",
    "            cv2.circle(mesh_view, pt, 3, color, -1)\n",
    "            # Add small label\n",
    "            if pt == left_eye_pts[0] or pt == right_eye_pts[0]:\n",
    "                cv2.putText(mesh_view, \"Eye\", (pt[0]+5, pt[1]-5), \n",
    "                           cv2.FONT_HERSHEY_SIMPLEX, 0.3, color, 1)\n",
    "        \n",
    "        # Draw mouth landmarks with color coding\n",
    "        for pt in mouth_pts:\n",
    "            color = (0, 255, 0) if mar < detector.MAR_THRESHOLD else (0, 0, 255)\n",
    "            cv2.circle(mesh_view, pt, 3, color, -1)\n",
    "            if pt == mouth_pts[0]:\n",
    "                cv2.putText(mesh_view, \"Mouth\", (pt[0]+5, pt[1]-5), \n",
    "                           cv2.FONT_HERSHEY_SIMPLEX, 0.3, color, 1)\n",
    "        \n",
    "        # Draw head pose lines with descriptions\n",
    "        cv2.line(mesh_view, left_eye_pt, right_eye_pt, (255, 0, 0), 2)\n",
    "        cv2.putText(mesh_view, \"Eye Line (Tilt)\", \n",
    "                   ((left_eye_pt[0] + right_eye_pt[0])//2 - 50, (left_eye_pt[1] + right_eye_pt[1])//2 - 10), \n",
    "                   cv2.FONT_HERSHEY_SIMPLEX, 0.4, (255, 0, 0), 1)\n",
    "        \n",
    "        cv2.line(mesh_view, nose_pt, chin_pt, (255, 255, 0), 2)\n",
    "        cv2.putText(mesh_view, \"Nose-Chin (Pitch)\", \n",
    "                   ((nose_pt[0] + chin_pt[0])//2 - 50, (nose_pt[1] + chin_pt[1])//2), \n",
    "                   cv2.FONT_HERSHEY_SIMPLEX, 0.4, (255, 255, 0), 1)\n",
    "        \n",
    "        # Add measurement labels on mesh view\n",
    "        cv2.putText(mesh_view, f\"EAR: {ear:.3f}\", (w-200, 80), \n",
    "                   cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 1)\n",
    "        cv2.putText(mesh_view, f\"MAR: {mar:.3f}\", (w-200, 110), \n",
    "                   cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 1)\n",
    "        cv2.putText(mesh_view, f\"Tilt: {roll_angle:.1f}¬∞\", (w-200, 140), \n",
    "                   cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 1)\n",
    "        \n",
    "        # Legend for colors\n",
    "        cv2.putText(mesh_view, \"Green: Normal\", (w-200, h-90), \n",
    "                   cv2.FONT_HERSHEY_SIMPLEX, 0.4, (0, 255, 0), 1)\n",
    "        cv2.putText(mesh_view, \"Red: Fatigue Indicator\", (w-200, h-70), \n",
    "                   cv2.FONT_HERSHEY_SIMPLEX, 0.4, (0, 0, 255), 1)\n",
    "        cv2.putText(mesh_view, \"Blue Lines: Measurements\", (w-200, h-50), \n",
    "                   cv2.FONT_HERSHEY_SIMPLEX, 0.4, (255, 0, 0), 1)\n",
    "        \n",
    "        # Overall fatigue status on mesh view\n",
    "        if fatigue_state.is_fatigued:\n",
    "            # Create a translucent overlay for warning\n",
    "            overlay = mesh_view.copy()\n",
    "            cv2.rectangle(overlay, (w//2-150, 50), (w//2+150, 100), (0, 0, 255), -1)\n",
    "            cv2.addWeighted(overlay, 0.3, mesh_view, 0.7, 0, mesh_view)\n",
    "            cv2.putText(mesh_view, \"FATIGUE DETECTED\", (w//2-140, 80), \n",
    "                       cv2.FONT_HERSHEY_SIMPLEX, 0.8, (255, 255, 255), 2)\n",
    "    \n",
    "    else:\n",
    "        # No face detected\n",
    "        normal_view = frame.copy()\n",
    "        mesh_view = frame.copy()\n",
    "        cv2.putText(normal_view, \"NO FACE DETECTED\", (30, h//2), \n",
    "                   cv2.FONT_HERSHEY_SIMPLEX, 1.0, (0, 0, 255), 2)\n",
    "        cv2.putText(mesh_view, \"NO FACE DETECTED\", (30, h//2), \n",
    "                   cv2.FONT_HERSHEY_SIMPLEX, 1.0, (0, 0, 255), 2)\n",
    "    \n",
    "    # Combine both views side by side\n",
    "    # Make sure both have same height, if not resize\n",
    "    if normal_view.shape[0] != mesh_view.shape[0]:\n",
    "        h = min(normal_view.shape[0], mesh_view.shape[0])\n",
    "        normal_view = cv2.resize(normal_view, (int(normal_view.shape[1] * h / normal_view.shape[0]), h))\n",
    "        mesh_view = cv2.resize(mesh_view, (int(mesh_view.shape[1] * h / mesh_view.shape[0]), h))\n",
    "    \n",
    "    combined = np.hstack((normal_view, mesh_view))\n",
    "    \n",
    "    # Add a vertical divider line\n",
    "    divider_x = normal_view.shape[1]\n",
    "    cv2.line(combined, (divider_x, 0), (divider_x, combined.shape[0]), (255, 255, 255), 2)\n",
    "    \n",
    "    # Add labels for each side\n",
    "    cv2.putText(combined, \"NORMAL VIEW\", (30, 60), \n",
    "               cv2.FONT_HERSHEY_SIMPLEX, 0.8, (255, 255, 255), 2)\n",
    "    cv2.putText(combined, \"ANALYZED VIEW\", (divider_x + 30, 60), \n",
    "               cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 255, 255), 2)\n",
    "    \n",
    "    # Show the combined view\n",
    "    cv2.imshow(\"Fatigue Detection System\", combined)\n",
    "    \n",
    "    # Exit on 'q'\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab5737d7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
